{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET - trainDataXV.csv\n",
    "- This is a small dataset to test if the code works\n",
    "- We will initially implement decision tree and logestic regression to the dataset to make sure things are working\n",
    "- We then will implement the cross-validation feature and data handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train and test dataset\n",
    "data_1_train = pd.read_csv(\"ATNT50/trainDataXY.txt\", header=None)\n",
    "data_1_test = pd.read_csv(\"ATNT50/testDataXY.txt\", header=None)\n",
    "\n",
    "# The data is in a form where the headers of each column is the class of the data, and the entire data is a column\n",
    "# We need to transpose this to make sure that each data is a row\n",
    "transposed_data_1_train = data_1_train.T\n",
    "transposed_data_1_test = data_1_test.T\n",
    "\n",
    "# Seperating Class y and Attributes X.\n",
    "X = transposed_data_1_train.iloc[:, 1:]\n",
    "y = transposed_data_1_train.iloc[:, 0]\n",
    "\n",
    "# Attribute X for the testDataXY.csv\n",
    "X_test = transposed_data_1_test.iloc[:, 1:]\n",
    "y_true = transposed_data_1_test.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers\n",
    "1. The expected classes are already given for the test data y_true = 1,4,5,2,3\n",
    "2. Decision tree classifier is implemented with result 1,3,5,2,3 - which is a 80% accuracy\n",
    "3. Logistic Regressor is implemented with result 1,4,5,2,3 - which is a 100% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>635</th>\n",
       "      <th>636</th>\n",
       "      <th>637</th>\n",
       "      <th>638</th>\n",
       "      <th>639</th>\n",
       "      <th>640</th>\n",
       "      <th>641</th>\n",
       "      <th>642</th>\n",
       "      <th>643</th>\n",
       "      <th>644</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "      <td>55</td>\n",
       "      <td>48</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>48</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>44</td>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>43</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>69</td>\n",
       "      <td>78</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>58</td>\n",
       "      <td>55</td>\n",
       "      <td>52</td>\n",
       "      <td>53</td>\n",
       "      <td>59</td>\n",
       "      <td>56</td>\n",
       "      <td>47</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>43</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>46</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>158</td>\n",
       "      <td>147</td>\n",
       "      <td>127</td>\n",
       "      <td>112</td>\n",
       "      <td>101</td>\n",
       "      <td>96</td>\n",
       "      <td>89</td>\n",
       "      <td>77</td>\n",
       "      <td>66</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>39</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>52</td>\n",
       "      <td>50</td>\n",
       "      <td>38</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>45</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "      <td>44</td>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>48</td>\n",
       "      <td>64</td>\n",
       "      <td>74</td>\n",
       "      <td>102</td>\n",
       "      <td>120</td>\n",
       "      <td>137</td>\n",
       "      <td>144</td>\n",
       "      <td>142</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>132</td>\n",
       "      <td>129</td>\n",
       "      <td>130</td>\n",
       "      <td>134</td>\n",
       "      <td>145</td>\n",
       "      <td>153</td>\n",
       "      <td>156</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>55</td>\n",
       "      <td>63</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>179</td>\n",
       "      <td>115</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>35</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>47</td>\n",
       "      <td>44</td>\n",
       "      <td>43</td>\n",
       "      <td>44</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>38</td>\n",
       "      <td>36</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>190</td>\n",
       "      <td>178</td>\n",
       "      <td>69</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "      <td>44</td>\n",
       "      <td>43</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>45</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>43</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "      <td>52</td>\n",
       "      <td>87</td>\n",
       "      <td>115</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>41</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "      <td>38</td>\n",
       "      <td>46</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>58</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows × 645 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9    ...  635  636  637  638  \\\n",
       "0     1   47   47   49   51   55   48   45   45   48  ...   41   44   42   41   \n",
       "1     1   64   65   69   78   79   80   95   93   85  ...   36   36   37   38   \n",
       "2     1   50   58   55   52   53   59   56   47   50  ...   44   44   43   42   \n",
       "3     1   39   30   28   46   65   81   86   86   83  ...  158  147  127  112   \n",
       "4     1   66   39   56   56   52   50   38   35   37  ...   49   45   42   43   \n",
       "5     1   51   48   64   74  102  120  137  144  142  ...  130  132  129  130   \n",
       "6     1   46   47   50   50   55   63   60   60   62  ...  179  115   38   38   \n",
       "7     1   37   35   30   28   28   26   27   26   25  ...   48   47   44   43   \n",
       "8     1   43   42   41   38   36   31   27   27   29  ...  190  178   69   44   \n",
       "9     2   37   37   37   38   39   39   39   39   57  ...   31   26   28   28   \n",
       "10    2   37   38   39   39   40   40   40   40   47  ...   26   27   28   27   \n",
       "11    2   35   37   37   38   38   39   38   45   77  ...   25   27   28   27   \n",
       "12    2   36   37   38   38   39   40   40   39   43  ...   25   26   27   26   \n",
       "13    2   34   36   36   37   37   38   37   38   64  ...   40   32   24   26   \n",
       "14    2   37   38   39   40   40   42   41   43   61  ...   27   29   28   27   \n",
       "15    2   38   38   39   39   39   37   52   87  115  ...   25   29   28   27   \n",
       "16    2   37   38   39   39   40   41   38   46   70  ...   25   27   28   27   \n",
       "17    2   39   40   40   41   42   42   41   58  101  ...   28   28   28   28   \n",
       "\n",
       "    639  640  641  642  643  644  \n",
       "0    41   43   45   45   46   46  \n",
       "1    38   38   37   36   35   34  \n",
       "2    42   40   39   37   33   30  \n",
       "3   101   96   89   77   66   60  \n",
       "4    44   46   44   42   41   38  \n",
       "5   134  145  153  156  159  159  \n",
       "6    37   36   36   35   36   36  \n",
       "7    44   45   43   42   40   39  \n",
       "8    46   44   43   42   43   42  \n",
       "9    27   28   27   27   21   60  \n",
       "10   27   26   26   26   26   27  \n",
       "11   27   26   27   27   27   27  \n",
       "12   26   27   27   27   26   26  \n",
       "13   28   27   26   27   26   27  \n",
       "14   27   27   28   27   26   27  \n",
       "15   27   27   27   26   41  128  \n",
       "16   27   27   27   27   23   87  \n",
       "17   28   27   27   28   23   58  \n",
       "\n",
       "[18 rows x 645 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transposed_data_1_train[]\n",
    "x = transposed_data_1_train[0].isin([1,2])\n",
    "# transposed_data_1_train.mean(axis=0)\n",
    "x\n",
    "transposed_data_1_train[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Class: \n",
      "[1, 4, 5, 2, 3]\n",
      "\n",
      "\n",
      "Decision Tree Prediction\n",
      "[1 3 5 2 3]\n",
      "Accuracy\n",
      "0.8\n",
      "\n",
      "\n",
      "Logistic Regression Classification\n",
      "[1 4 5 2 3]\n",
      "Accuracy\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Expected Class\n",
    "print(\"Expected Class: \")\n",
    "print(list(y_true))\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf = clf.fit(X, y)\n",
    "y_predict_dec = clf.predict(X_test)\n",
    "print(\"Decision Tree Prediction\")\n",
    "print(y_predict_dec)\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(y_true, y_predict_dec))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial', max_iter=107).fit(X, y)\n",
    "y_predict_log = clf.predict(X_test)\n",
    "print(\"Logistic Regression Classification\")\n",
    "print(y_predict_log)\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(y_true, y_predict_log))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add new Dataset\n",
    "- Adding class of 26 classes and 39 data points for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total 40 classes. each class has 10 images. Total 40*10=400 images\n",
    "# 1st row is cluster labels. \n",
    "# 2nd-end rows: each column is a feature vectors (vector length=28x23).\n",
    "face_train = pd.read_csv(\"ATNTFaceImages400.txt\", header=None)\n",
    "\n",
    "# Hand-written-26-letter\n",
    "# 1st row is cluster labels. \n",
    "# 2nd-end rows: each column is a feature vectors (vector length=20x16).\n",
    "# Total 26 classes. each class has 39 images. Total 26*39=1014 images.\n",
    "handw_test = pd.read_csv(\"HandWrittenLetters.txt\", header=None)\n",
    "\n",
    "# The data is in a form where the headers of each column is the class of the data, and the entire data is a column\n",
    "# We need to transpose this to make sure that each data is a row\n",
    "face_t = face_train.T\n",
    "handw_t = handw_test.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>635</th>\n",
       "      <th>636</th>\n",
       "      <th>637</th>\n",
       "      <th>638</th>\n",
       "      <th>639</th>\n",
       "      <th>640</th>\n",
       "      <th>641</th>\n",
       "      <th>642</th>\n",
       "      <th>643</th>\n",
       "      <th>644</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "      <td>55</td>\n",
       "      <td>48</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>48</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>44</td>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>43</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>69</td>\n",
       "      <td>78</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>58</td>\n",
       "      <td>55</td>\n",
       "      <td>52</td>\n",
       "      <td>53</td>\n",
       "      <td>59</td>\n",
       "      <td>56</td>\n",
       "      <td>47</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>43</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>46</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>158</td>\n",
       "      <td>147</td>\n",
       "      <td>127</td>\n",
       "      <td>112</td>\n",
       "      <td>101</td>\n",
       "      <td>96</td>\n",
       "      <td>89</td>\n",
       "      <td>77</td>\n",
       "      <td>66</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>39</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>52</td>\n",
       "      <td>50</td>\n",
       "      <td>38</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>45</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "      <td>44</td>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>48</td>\n",
       "      <td>64</td>\n",
       "      <td>74</td>\n",
       "      <td>102</td>\n",
       "      <td>120</td>\n",
       "      <td>137</td>\n",
       "      <td>144</td>\n",
       "      <td>142</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>132</td>\n",
       "      <td>129</td>\n",
       "      <td>130</td>\n",
       "      <td>134</td>\n",
       "      <td>145</td>\n",
       "      <td>153</td>\n",
       "      <td>156</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>55</td>\n",
       "      <td>63</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>179</td>\n",
       "      <td>115</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>35</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>47</td>\n",
       "      <td>44</td>\n",
       "      <td>43</td>\n",
       "      <td>44</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>38</td>\n",
       "      <td>36</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>190</td>\n",
       "      <td>178</td>\n",
       "      <td>69</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "      <td>44</td>\n",
       "      <td>43</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>28</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>49</td>\n",
       "      <td>46</td>\n",
       "      <td>45</td>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 645 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  635  636  637  638  \\\n",
       "0    1   47   47   49   51   55   48   45   45   48  ...   41   44   42   41   \n",
       "1    1   64   65   69   78   79   80   95   93   85  ...   36   36   37   38   \n",
       "2    1   50   58   55   52   53   59   56   47   50  ...   44   44   43   42   \n",
       "3    1   39   30   28   46   65   81   86   86   83  ...  158  147  127  112   \n",
       "4    1   66   39   56   56   52   50   38   35   37  ...   49   45   42   43   \n",
       "5    1   51   48   64   74  102  120  137  144  142  ...  130  132  129  130   \n",
       "6    1   46   47   50   50   55   63   60   60   62  ...  179  115   38   38   \n",
       "7    1   37   35   30   28   28   26   27   26   25  ...   48   47   44   43   \n",
       "8    1   43   42   41   38   36   31   27   27   29  ...  190  178   69   44   \n",
       "9    1   33   34   28   32   28   26   27   28   31  ...   48   50   50   50   \n",
       "\n",
       "   639  640  641  642  643  644  \n",
       "0   41   43   45   45   46   46  \n",
       "1   38   38   37   36   35   34  \n",
       "2   42   40   39   37   33   30  \n",
       "3  101   96   89   77   66   60  \n",
       "4   44   46   44   42   41   38  \n",
       "5  134  145  153  156  159  159  \n",
       "6   37   36   36   35   36   36  \n",
       "7   44   45   43   42   40   39  \n",
       "8   46   44   43   42   43   42  \n",
       "9   51   49   46   45   39   37  \n",
       "\n",
       "[10 rows x 645 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_t[face_t[0].isin([1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Handling \n",
    "### Idea of handling data\n",
    "1. Take n% of the data for testing\n",
    "2. Take 1-(n%) of the data for training\n",
    "---\n",
    "\n",
    "- We now take n = 10%? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating Class y and Attributes X.\n",
    "# \n",
    "\n",
    "# Number of rows in test\n",
    "face_rows = len(face_t)\n",
    "handw_rows = len(handw_t)\n",
    "\n",
    "# FACE\n",
    "# Face_Test and train split\n",
    "face_t_test = face_t.iloc[:int(face_rows/10)]\n",
    "face_t_train = face_t.iloc[int(face_rows/10): face_rows]\n",
    "\n",
    "# Face Seperating Class y and Attributes X.\n",
    "# For test\n",
    "face_test_X = face_t_test.iloc[:, 1:]\n",
    "face_test_y = face_t_test.iloc[:, 0]\n",
    "# For train\n",
    "face_train_X = face_t_train.iloc[:, 1:]\n",
    "face_train_y = face_t_train.iloc[:, 0]\n",
    "\n",
    "\n",
    "# HANDWRITING\n",
    "# Handwriting_Test and train split\n",
    "handw_t_test = handw_t.iloc[:int(handw_rows/10)]\n",
    "handw_t_train = handw_t.iloc[int(handw_rows/10): handw_rows]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Handwriting Seperating Class y and Attributes X.\n",
    "# for test\n",
    "handw_test_X = handw_t_test.iloc[:, 1:]\n",
    "handw_test_y = handw_t_test.iloc[:, 0]\n",
    "# For train\n",
    "handw_train_X = handw_t_train.iloc[:, 1:]\n",
    "handw_train_y = handw_t_train.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def LogReg(X,y,X_test,y_test):\n",
    "    clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial', max_iter=500).fit(X, y)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return y_pred,accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Classifier\n",
    "from sklearn.svm import SVC\n",
    "def SVClassifier(X,y,X_test,y_test):\n",
    "    clf = SVC(gamma='auto')\n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return y_pred,accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "def knn(X,y,X_test,y_test):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "    neigh.fit(X, y)\n",
    "    y_pred = neigh.predict(X_test)\n",
    "    return y_pred, accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickDataClass(filename, class_ids):\n",
    "    class_ids = letter_2_digit_convert(class_ids)\n",
    "    dataset = pd.read_csv(filename, header=None)\n",
    "    dataset_t = dataset.T\n",
    "    return dataset_t.loc[dataset_t[0].isin(class_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letter_2_digit_convert(ids):\n",
    "    return [ord(c)-97+1 for c in ids.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData2TestTrain(dataset, number_per_class,  test_instances):\n",
    "    classes = list(dataset.iloc[:,0].unique())\n",
    "    columns = dataset.columns.stop\n",
    "    train = pd.DataFrame([], columns=[i for i in range(0,columns)])\n",
    "    test = pd.DataFrame([], columns=[i for i in range(0,columns)])\n",
    "    \n",
    "#     Split test_inst in number_per_class\n",
    "    \n",
    "    for cls in classes:\n",
    "        class_data = dataset[dataset[0]==cls]\n",
    "#         print(test_instances)\n",
    "#         print(class_data[test_instances[0]:test_instances[1]])\n",
    "        test = test.append(class_data[test_instances[0]:test_instances[1]])\n",
    "        train = train.append(class_data[0:test_instances[0]])\n",
    "        train = train.append(class_data[test_instances[1]:number_per_class])\n",
    "#         print(test)\n",
    "\n",
    "#     split X and yt\n",
    "    test_attr = test.iloc[:, 1:columns]\n",
    "    test_class = test.iloc[:, 0]\n",
    "    test_class=test_class.astype('int')\n",
    "    train_attr = train.iloc[:, 1:columns]\n",
    "    train_class = train.iloc[:, 0]\n",
    "    train_class=train_class.astype('int')\n",
    "    return train_attr, train_class, test_attr, test_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question A RESULT: \n",
      "SVM\n",
      "{'ypred': array([ 1,  1,  1,  1,  1,  1,  1,  2,  1,  2,  2,  2,  1,  2,  2,  2,  2,\n",
      "        2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,\n",
      "        4,  4,  5,  5,  5,  5,  5,  3,  5,  3,  5, 26, 26, 26, 26, 26,  4,\n",
      "       26, 26, 26]), 'accuracy': 0.9074074074074074}\n",
      "Logistic Regression\n",
      "{'ypred': array([ 1,  1,  1,  1,  1,  1,  1,  2,  1,  2,  2,  2,  1,  2,  2,  2,  2,\n",
      "        2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,\n",
      "        4,  4,  5,  5,  5,  5,  5,  2,  5,  3,  5, 26, 26, 26, 26, 26,  4,\n",
      "       26, 26, 26]), 'accuracy': 0.9074074074074074}\n",
      "KNN Regression\n",
      "{'ypred': array([ 1,  2,  1,  1,  2,  1,  1,  2,  1,  1,  2,  2,  1,  2,  2,  5, 26,\n",
      "        2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,\n",
      "        1,  4,  5,  5,  5,  5,  5,  3,  5,  3,  5, 26, 26, 26, 26, 26, 26,\n",
      "       26, 26, 26]), 'accuracy': 0.8148148148148148}\n"
     ]
    }
   ],
   "source": [
    "# QUESTION A\n",
    "\n",
    "result = {}\n",
    "filename = \"HandWrittenLetters.txt\"\n",
    "classes = \"ABCDEZ\"\n",
    "dataset = pickDataClass(filename, classes)\n",
    "number_per_class=39\n",
    "k=2\n",
    "test_instances=\"30:39\"\n",
    "test_instances=[int(i) for i in test_instances.split(':')]\n",
    "result = {}\n",
    "train_attr, train_class, test_attr, test_class = splitData2TestTrain(dataset,number_per_class,test_instances)\n",
    "\n",
    "ypred, accuracy = SVClassifier(train_attr,train_class,test_attr,test_class)\n",
    "result[\"svm\"]={\n",
    "    \"ypred\": ypred,\n",
    "    \"accuracy\": accuracy\n",
    "}\n",
    "\n",
    "ypred, accuracy = LogReg(train_attr,train_class,test_attr,test_class)\n",
    "result[\"lin\"]={\n",
    "    \"ypred\": ypred,\n",
    "    \"accuracy\": accuracy\n",
    "}\n",
    "\n",
    "ypred, accuracy = knn(train_attr,train_class,test_attr,test_class)\n",
    "result[\"knn\"]={\n",
    "    \"ypred\": ypred,\n",
    "    \"accuracy\": accuracy\n",
    "}\n",
    "\n",
    "print(\"Question A RESULT: \")\n",
    "print(\"SVM\")\n",
    "print(result[\"svm\"])\n",
    "print(\"Logistic Regression\")\n",
    "print(result[\"lin\"])\n",
    "print(\"KNN Regression\")\n",
    "print(result[\"knn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 5 fold accuracies\n",
      "[0.9875, 1.0, 1.0, 0.975, 0.9625]\n",
      "MEAN:  0.985\n",
      "SVM 5 fold accuracies\n",
      "[0.75, 0.7875, 0.7125, 0.5875, 0.65]\n",
      "MEAN:  0.6975\n",
      "LOGISTIC REGRESSION 5 fold accuracies\n",
      "[0.9125, 0.925, 0.9625, 0.9875, 0.9375]\n",
      "MEAN:  0.945\n"
     ]
    }
   ],
   "source": [
    "# QUESTION B\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "result = {}\n",
    "filename = \"ATNTFaceImages400.txt\"\n",
    "dataset = pd.read_csv(filename, header=None)\n",
    "dataset = dataset.T\n",
    "folds = StratifiedKFold(n_splits=5)\n",
    "\n",
    "log = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial', max_iter=500)\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "svm = SVC(gamma='auto')\n",
    "\n",
    "\n",
    "score_knn=[]\n",
    "score_svm=[]\n",
    "score_log=[]\n",
    "\n",
    "X,y = dataset.iloc[:,1:], dataset.iloc[:, 0]\n",
    "for train_index, test_index in folds.split(X,y):\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_index],X.iloc[test_index],y.iloc[train_index],y.iloc[test_index]\n",
    "    score_knn.append(get_score(log, X_train, X_test, y_train, y_test))  \n",
    "    score_svm.append(get_score(svm, X_train, X_test, y_train, y_test))\n",
    "    score_log.append(get_score(knn, X_train, X_test, y_train, y_test))\n",
    "\n",
    "print(\"KNN 5 fold accuracies\")\n",
    "print(score_knn)\n",
    "print(\"MEAN: \", sum(score_knn)/len(score_knn) )\n",
    "print(\"SVM 5 fold accuracies\")\n",
    "print(score_svm)\n",
    "print(\"MEAN: \", sum(score_svm)/len(score_svm) )\n",
    "print(\"LOGISTIC REGRESSION 5 fold accuracies\")\n",
    "print(score_log)\n",
    "print(\"MEAN: \", sum(score_log)/len(score_log) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class Centroid:\n",
    "    def fit(self, X,y):\n",
    "        self.meanX = pd.DataFrame([], columns= X.columns)\n",
    "        classes = list(y.unique())\n",
    "        self.meanY = pd.Series(classes)\n",
    "        for cls in classes:\n",
    "            self.meanX=self.meanX.append(X[y==cls].mean(),ignore_index=True)\n",
    "            \n",
    "    def predict(self, X_test):\n",
    "        pred_list = []\n",
    "        for ri,row in X_test.iterrows():\n",
    "            min_dist = float('inf')\n",
    "            min_ind = -1\n",
    "            for mean_index, mean_val in self.meanX.iterrows():\n",
    "                dist = self.euclidean_distance(mean_val, row)\n",
    "                if(dist<min_dist):\n",
    "                    min_dist = dist\n",
    "                    min_ind = mean_index\n",
    "            pred_list.append(self.meanY[min_ind])\n",
    "        return pred_list\n",
    "\n",
    "    # Calculate the Euclidean distance between two vectors\n",
    "    def euclidean_distance(self, row1, row2):\n",
    "        distance = 0.0\n",
    "        for i in range(1,len(row1)):\n",
    "            distance += (row1[i] - row2[i])**2\n",
    "        return math.sqrt(distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEGCAYAAACQO2mwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxU5dn/8c9FgAQIkCCbQCCAICJL0ACCrVVrFXfct4qoVdG6tD+tS+tWbV1abevz1KVYEXBDBBfcarWulTXsO7IT1kAIe0KW6/fHDD4RMzAgkzMz+b5fL17MnHOfmeswYb459znnvs3dERERqUqtoAsQEZH4pZAQEZGIFBIiIhKRQkJERCJSSIiISES1gy7gUGnatKlnZ2cHXYaISEKZOnXqRndvFml90oREdnY2eXl5QZchIpJQzGzFvtaru0lERCJSSIiISEQKCRERiUghISIiESkkREQkIoWEiIhEpJAQEZGIFBIiUqO4O1OWF/LKpBWUV2iqhP1JmpvpRET2ZefuMt6ZsYYR45ezYN02AL5atJG/XZpDWp2UgKuLXwoJEUlqKzbt4KUJKxidt4qtxWV0admQR8/vzvbiMv74wXwGDZvM84NyaVyvTtClxiWFhIgknYoK54tvChg5fjmfLyogxYzTurXkqn7Z9M7OxMwAaNE4jdtHz+CSf0xgxDV9aNEoLeDK449CQkSSxpadpbwxdRUvTVzBik07aZqeyi0nd+LyPm1p2fj7AXBOz1Y0qV+XG17K4/xnxjPimj4c0Tw9gMrjlyXLHNe5ubmuAf5Eaqb5a7cycsJy3pq+muLSCnLbZXJlv3ac3u1w6tbe//U5s/O3cPXwyZRXOMMG96ZX28zYFx0nzGyqu+dGXK+QEJFEVFpewUdz1zFy/AomLy8ktXYtBua05sp+7ejWuvEBv96KTTu48oXJFGwr4ZkrjuGkLs1jUHX8UUiISFLZsK2Y1yat4tXJK1i/tYSsJvW48rh2XJybRUb9uj/otQu2lXD18MnMX7uNxy/owYXHtjlEVcev/YWEzkmISNxzd6at3MyI8Sv4cM5aSsudEzo345Hz2nHikc1JqWWH5H2aNUxl1PX9uOGlPO54YyYbt5dwwwkdvj3RXRMpJEQkbhWXljNuxhpGTFjO3DVbaZham58f144rj2tHh2axOcGcnlqbYYN7c8cbs3jswwVs2FrCvWceRa1DFESJRiEhInFnVeFOXp64gtfzVlG0s5QjWzTkj+d1Y2BOaxqkxv5rK7V2Ck9dkkPT9LoM+3oZG7eX8MRFPaM6CZ5sFBIiEhcqKpyvFm9k5PjlfLpwA7XMOO3oFgzql03f9k2qvcunVi3j/rO60rxhGo//awGFO3bz3JXHkl4NIRVPatbeikjc2Vpcypi8fF6auIJlG3fQNL0uN590BJf3bcvhjesFWpuZceOJHWnWMJW7xs7i0qETeHFwH5o1TA20ruqkkBCRQCxct+3bext27i6nV9sM/nZJDqd3b0lq7fgaS+nCY9vQpEEdbnplGhc+N56R1/Sh3WENgi6rWugSWBGpNqXlFXw8bz0jJyxn4tJC6tauxbk9WzGoXzbd2xz4vQ3VbdrKzVwzfAq1axnDr+5zUPdjxBvdJyEigSvYVsKoySt5ZdJK1m0tpnVGPa7sF7q3oUmDH3ZvQ3VbvGE7Vw2bTNHO3QwdlMvxRzQNuqQfJNCQMLMBwFNACvBPd39sr/VtgRFARrjN3e7+gZllA/OBheGmE919yL7eSyEhEl/cnemrihg5fjnvzw7d2/DjTk0Z1C+bk7scunsbgrBuSzFXDZvM0o3befLiHM7p2Srokg5aYDfTmVkK8DTwMyAfmGJm49x9XqVm9wKj3f1ZM+sKfABkh9ctcfecWNUnIrFRXFrOuzPXMHLCCmav3kJ6am2u6NuOnx/XLmkGz2vZOI3RQ/px3Yg8bn1tOpu2l3D18e2DLismYnniug+w2N2XApjZKOBcoHJIONAo/LgxsCaG9YhIDK0q3Mkrk1by+pSVbN5ZSqfm6Tw8sBvn9WqdlJeNNq5Xh5HX9uG2UdP5/bvz2LCthDtPOzLp7s6O5SfXGlhV6Xk+0HevNg8C/zazW4AGwCmV1rU3s+nAVuBed/8qhrWKyEFwd75evIkRE5bzn/nrATi1a0sG9W9Hvw6HJd0X5t7S6qTwzBXHct87c3j28yUUbCvh0fO7UycleW66i2VIVPXTsfcJkMuA4e7+pJn1A14ys27AWqCtu28ys2OBt83saHff+p03MLseuB6gbdu2h34PRKRK24pLGTs1n5ETV7C0YAdNGtTlxhM7cnnfdrTOCPbehuqWUsv448BuNG+Yyt8++YbCHbt5+vJjqFc3vi7jPVixDIl8IKvS8zZ8vzvpWmAAgLtPMLM0oKm7bwBKwsunmtkSoDPwnTPT7j4UGAqhE9ex2AkR+T+LN2xjxPgVvDktnx27y+mZlcFfLu7JGd0Pr9HzRJsZvzqlM03TU7n/nTlc/s+JDLuqN5kJduVWVWIZElOATmbWHlgNXApcvleblcBPgeFmdhSQBhSYWTOg0N3LzawD0AlYGsNaRWQf3J3nv1rKox8uoE6tWpzV83AG9csmJysj6NLiys+Pa0fT9FRuHTU9dNPdtX0T/sgqZh1n7l4G3Ax8ROhy1tHuPtfMHjKzc8LNbgeuM7OZwGvAYA9dk3sCMCu8fAwwxN0LY1WriES2u6yCu8fO5pEPFnB6t5ZMuOdk/nJxjgIiggHdWvLSNX3YsK2E85/5mgXrtu5/ozimm+lEJKKinbsZ8vJUJi4t5JaTj+DXp3SusUNmH6gF67Zy1bDJ7NxdzgtX9aZP+yZBl1Sl/d0nkTyn4EXkkFpasJ3znhnPtBVF/PWSntx+6pEKiAPQpWUjxt7Yn2YNU/n5C5P4aO66oEs6KAoJEfme8Ys3MvDpr9m6q5RXr+vLeb2SfxrPWGiTWZ8xQ/rT9fBG3PjyVF6ZtCLokg6YQkJEvuO1ySsZNGwyLRql8fYvjyc3Oz67SRJFkwZ1efW6vvykczN+99YcnvrkGxKpm18hISIAlFc4f3hvHve8OZvjj2jK2Jv6k9WkftBlJYX6dWszdFAuFxzThr9+soh7355DeUViBEXy3SsvIgdse0kZt702nf8s2MDg/tnce+ZR1E6iu4bjQZ2UWjxxUQ+aN0rl2c+XsGn7bv52aU7c31+inwKRGm510S4ufHY8ny8q4OFzj+bBc45WQMSImXHXgC7cf1ZX/jV3HYOGTWbLrtKgy9on/SSI1GDTV27m3L9/zerNu3hxcG+u7JcddEk1wjU/as//XNaL6Ss3c8k/JrB+a3HQJUWkkBCpod6duYZLhk6kXt1avHlTf07o3CzokmqUc3q24sXBfVhVuJPznxnPkoLtQZdUJYWESA3j7jz1yTfc8tp0erZpzNs3HU+nFg2DLqtG+lGnprx+Qz9Kysq58NnxTF+5OeiSvkchIVKDFJeWc9uoGfz1k0Wcf0xrXv5FXw5LTw26rBqtW+vGjL2xP43q1eHy5yfx2cINQZf0HQoJkRqiYFsJlz0/kXEz13DngCN58qKepNaO7ytraop2hzVgzJD+dGzegF+MyGPM1PygS/qWQkKkBliwbisDn/6a+Wu38uwVx3DTiUck/YRAiaZZw1RGXd+P4zo04Y43ZvLcF0vi4qY7hYRIkvt0wXoueGY8ZRUVvHFDf07vfnjQJUkE6am1GTa4N2f3bMVjHy7g4ffmUxHwTXe6mU4kSbk7w75ezh/fn0fXVo3456DetGycFnRZsh+ptVN46pIcmqbXZdjXy9i4vYQnLupJ3drB/E6vkBBJQqXlFTwwbi6vTlrJaUe34K+X5FC/rv67J4patYz7z+pK84ZpPP6vBRTu2M1zVx5Lemr1f4bqbhJJMlt2ljL4xcm8OmklN57YkWevOFYBkYDMjBtP7MgTF/VkwtJNXDZ0IgXbSqq9DoWESBJZvnEH5z37NZOXFfLnC3tw14AumgMiwV14bBv+OSiXxRu2c+Fz41mxaUe1vr9CQiRJTFy6iYHPfE3hjt28fG1fLsrNCrokOURO6tKcV67ry5ZdpVzw7HjmrN5Sbe+tkBBJAqPzVnHlC5M4rEFd3vnl8fTtcFjQJckhdkzbTMYM6U9q7RQu+ccEvl68sVreVyEhksAqKpxHP5zPnWNmcVyHw3jzpuNpd1iDoMuSGDmieTpjb+xPm8z6DH5xMu/OXBPz91RIiCSonbvLGPLyVP7xxVKu6NuWYYN707henaDLkhhr2TiN0UP60Ssrk1tHTefFr5fF9P0UEiIJaO2WXVz03AQ+mb+eB87uyh8GdqOO5oCoMRrXq8PIa/twatcW/P7deTz+rwUxuztb18WJJJhZ+UX8YkQeO3eX88Lg3px0ZPOgS5IApNVJ4ZkrjuW+d+awtmgX7hCLkVYUEiIJ5IPZa/l/o2dwWINUxt7YlyNbaojvmiyllvHHgd0or/CYXeqskBBJAO7OM58v4c8fLeSYthkMHZRLUw3xLYRuuqudErt7YRQSInGupKyce8bO5s3pqzk3pxWPX9CDtDoa4luqh0JCJI5t2l7CDS9NJW/FZm7/WWduPllDfEv1UkiIxKlv1m/jmhFT2LC1hL9f3ouzerQKuiSpgRQSInHoi0UF3PzKNFLrpPD6Df3IycoIuiSpoRQSInFm5ITlPDhuLke2bMQ/r8qldUa9oEuSGkwhIRInysorePi9eYyYsIJTjmrOU5f2okEA8weIVKafQJE4sLW4lJtfnc6Xiwq47sftufv0o0jREN8SBxQSIgFbuWkn146YwrKNO3js/O5c2qdt0CWJfEshIRKgKcsLueGlqZRXOCOv7UP/jk2DLknkOxQSIgF5c1o+d4+dTevMerxwVS4dmqUHXZLI9ygkRKpZRYXzl48X8ffPFtOvw2E8+/NjyKhfN+iyRKqkkBCpRrt2l3P7GzP4YPY6LuuTxUPnaohviW8x/ek0swFmttDMFpvZ3VWsb2tmn5nZdDObZWZnVFp3T3i7hWZ2WizrFKkO67cWc8nQCXw4Zx33nnkUj5zXXQEhcS9mRxJmlgI8DfwMyAemmNk4d59Xqdm9wGh3f9bMugIfANnhx5cCRwOtgE/MrLO7l8eqXpFYmrN6C78YkcfW4lKevzKXU7q2CLokkajE8teYPsBid1/q7ruBUcC5e7VxoFH4cWNgz4St5wKj3L3E3ZcBi8OvJ5JQCraVMHrKKi56bgK1DMYM6a+AkIQSy3MSrYFVlZ7nA333avMg8G8zuwVoAJxSaduJe23beu83MLPrgesB2rbVteUSrOLScuau2cqMVUVMX7mZGauKyN+8C4CeWRk8P+hYmjdMC7hKkQMTy5Co6nbRvSdhvQwY7u5Pmlk/4CUz6xbltrj7UGAoQG5ubmwmeBWpgruzsnAn01cWfRsK89ZupbQ89GPYOqMeOVkZDO6fTU5WBjlZGdTW+QdJQLEMiXwgq9LzNvxfd9Ie1wIDANx9gpmlAU2j3Fak2mzZVcqs/KJvQ2HGqiIKd+wGoH7dFHq0acy1P+pAr7YZ9MrKoHkjHTFIcohlSEwBOplZe2A1oRPRl+/VZiXwU2C4mR0FpAEFwDjgVTP7C6ET152AyTGsVeRbZeUVLFy/7TuBsHjDdiA00fwRzdI55ajm5GRl0qttBp2ap+soQZJWzELC3cvM7GbgIyAFGObuc83sISDP3ccBtwPPm9mvCXUnDXZ3B+aa2WhgHlAG/FJXNkmsrNtSzIxVm5m+sojpq4qYnb+FXaWhH7fDGtQlJyuDgTmtyMnKpEdWYxql1Qm4YpHqY6Hv5MSXm5vreXl5QZchcW7X7nJmr97ybSjMWFXE2i3FANRJMY5u1ZicrIxwt1EmWU3qabpQSWpmNtXdcyOt1x3XkrQqKpxlm3YwY2UR08OhsGDdNsorQr8YZTWpR+/sJt+GQtdWjUitnRJw1SLxRSEhSWPzjt3MyC8Kh0IRM1cVsWVXKQDpqbXpmdWYG3/SMXS1UdsMmqanBlyxSPxTSEhCKi2vYMHabUxftfnbUFi2cQcAtQw6t2jIGd1b0isrk5y2GXRslq5JfEQOgkJC4p67s2ZLcegGtfB5hNmrt1BSVgFAs4ap9MrK4KLcNvTKyqRHm8aa9lPkENH/JIlL+Zt38u7Mtd/eubxhWwkAdWvXonvrxlx5XDty2mbQq20mrRqn6eSySIwoJCTuTFleyHUj8yjaWUr7pg04/oim9Gobumu5S8tG1K2texJEqotCQuLKuzPXcPvombTJrMebN/bXbG0iAVNISFxwd577YimP/2sBfbKbMHTQsZqtTSQOKCQkcKXlFdz/zhxem7yKc3q24s8X9dD9CiJxYr+du2Z2s5llVkcxUvNsKy7l2hF5vDZ5FTefdAR/uyRHASESR6I5kmhJaFa5acAw4CNPlrE8JFBrt+zi6hen8M2G7Tx+QXcu6a05QUTizX6PJNz9XkKjsL4ADAa+MbNHzKxjjGuTJDZ3zRYGPv01+Zt38eLg3goIkTgV1bWE4SOHdeE/ZUAmMMbM/hTD2iRJfbZwAxc/N4FaZoy5sR8ndG4WdEkiEsF+u5vM7FbgKmAj8E/gN+5eama1gG+AO2NboiSTVyet5L535nBki4a8eHVvWmhyHpG4Fs05iabA+e6+ovJCd68ws7NiU5Ykm4oK508fLeS5L5Zw0pHN+N/LjyFdQ2eIxL1o/pd+ABTueWJmDYGu7j7J3efHrDJJGsWl5dz+xkzen7WWK/q25ffnHK2Z3EQSRDQh8SxwTKXnO6pYJlKlwh27uX5kHnkrNvPbM7pw3Y87aJwlkQQSTUhY5Utew91M6ieQ/Vq2cQdXvziZNVuKefryYzizx+FBlyQiByiaY/6lZnarmdUJ/7kNWBrrwiSx5S0v5PxnvmZrcRmvXddXASGSoKIJiSFAf2A1kA/0Ba6PZVGS2N6btYbL/zmJjPp1efPG/hzbrknQJYnIQdpvt5G7bwAurYZaJMFVHqSvd3YmQ6/MJbOBBukTSWTR3CeRBlwLHA18e1G7u18Tw7okwZSVV3D/uLm8OmklZ/dsxZ8v7EFaHY3BJJLooulueonQ+E2nAV8AbYBtsSxKEsv2kjKuHZHHq5NWctOJHXnqkhwFhEiSiOYqpSPc/SIzO9fdR5jZq8BHsS5MEsO6LcVcPXwKi9Zv49Hzu3NZH43BJJJMogmJ0vDfRWbWjdD4Tdkxq0gSxrw1W7lm+BS2l5QxbHBvfqIxmESSTjQhMTQ8n8S9wDggHbgvplVJ3PtiUQE3vTyVhml1GH1DP7q2ahR0SSISA/sMifAgflvdfTPwJdChWqqSuPba5JXc+/YcOrdoyIuDe9OysQbpE0lW+zxx7e4VwM3VVIvEuYoK5/F/LeCeN2fzoyOa8saQfgoIkSQXTXfTx2Z2B/A6oXGbAHD3wsibSLIpLi3njjdm8t6stVzety0PaZA+kRohmpDYcz/ELystc9T1VGNs3rGb68KD9N19ehduOEGD9InUFNHccd2+OgqR+LR84w6uHj6F1UW7+PvlvTirR6ugSxKRahTNHdeDqlru7iMPfTkST6auKOS6kVNxd179RV9yszUGk0hNE013U+9Kj9OAnwLTAIVEEnt/1lp+PXoGrRqnMfzqPmQ3bRB0SSISgGi6m26p/NzMGhMaqkOSkLsz9MulPPrhAnLbZTJ0UC5NNEifSI11MJMH7QQ6HepCJHhl5RU8MG4ur0xayZk9DufJi3pqDCaRGi6acxLvErqaCUL3VXQFRseyKKl+20vKuOXVaXy2sIAhP+nInacdSa1auoJJpKaL5kjiiUqPy4AV7p4fo3okAOu2FHPN8CksXL+NR87rzuV9NUifiIREExIrgbXuXgxgZvXMLNvdl+9vQzMbADwFpAD/dPfH9lr/V+Ck8NP6QHN3zwivKwdm76nB3c+JolY5QPPXhgbp27qrlBeuyuXEI5sHXZKIxJFoQuINQtOX7lEeXta76uYhZpYCPA38jNC0p1PMbJy7z9vTxt1/Xan9LUCvSi+xy91zoqhPDtKXiwq46ZVppKfW5o0h/TVIn4h8TzTjKtR29917noQfR3O5Sx9gsbsvDW8zCjh3H+0vA16L4nXlEBg1eSVXD59Cm8x6vPVLBYSIVC2akCgws2+7eszsXGBjFNu1BlZVep4fXvY9ZtYOaA98WmlxmpnlmdlEMxsYYbvrw23yCgoKoihJKiqcP3+0gLvfnM3x4UH6Dm9cL+iyRCRORdPdNAR4xcz+Hn6eD1R5F/Zeqro0xqtYBnApMMbdyysta+vua8ysA/Cpmc129yXfeTH3ocBQgNzc3EivLWElZeX85o1ZjJu5hsv6ZPHQud2oo0H6RGQformZbglwnJmlA+bu0c5vnQ9kVXreBlgToe2lfHcAQdx9TfjvpWb2OaHzFUu+v6lEY/OO3dzw0lQmLy/krgFdGPITDdInIvu3318jzewRM8tw9+3uvs3MMs3sD1G89hSgk5m1N7O6hIJgXBWvfySQCUyotCzTzFLDj5sCxwPz9t5WorNi0w7Of3Y8M1YV8b+X9eLGEzsqIEQkKtH0NZzu7kV7noRnqTtjfxu5exmhCYs+AuYDo919rpk9VPkcB6ET1qPcvXJ30VFAnpnNBD4DHqt8VZREb+qKzZz3zHg279zNK9f15eyeGsVVRKIXzTmJFDNLdfcSCN0nAaRG8+Lu/gHwwV7L7t/r+YNVbDce6B7Ne0hkH85ey69en0HL8CB97TVIn4gcoGhC4mXgP2b2Yvj51cCI2JUkP5S78/xXoUH6emVl8PygXA5LjyrXRUS+I5oT138ys1nAKYSuWPoX0C7WhcnBKSuv4MF35/LyxJWc2f1wnrxYg/SJyMGLdhTYdUAFcDGwDBgbs4rkoO3cXcbNr07n0wUbuOGEDtw1oIsG6RORHyRiSJhZZ0JXJF0GbAJeJ3QJ7EmRtpFgPfrBAj5buIGHB3bjyuN0sCciP9y+jiQWAF8BZ7v7YgAz+/U+2kuAJi8r5KWJK7jm+PYKCBE5ZPZ1CewFhLqZPjOz583sp1R9F7UErLi0nLvHzqJNZj3uOK1z0OWISBKJGBLu/pa7XwJ0AT4Hfg20MLNnzezUaqpPovC/n37D0o07eOS87tSvezCTDYqIVG2/N9O5+w53f8XdzyI0tMYM4O6YVyZRmbtmC899sZQLj23DCZ2bBV2OiCSZAxrdzd0L3f0f7n5yrAqS6JWVV3DX2Flk1q/LvWceFXQ5IpKE1DeRwF747zLmrN7K05cfQ0b9aKb4EBE5MBonOkEt27iDv3y8iFO7tuCM7i2DLkdEkpRCIgG5O/e8OYu6tWvx8MBuGtFVRGJGIZGARk1ZxcSlhfzujKNo0Sgt6HJEJIkpJBLMui3FPPL+fPp1OIxLemftfwMRkR9AIZFA3J373pnD7vIKHj2/u7qZRCTmFBIJ5IPZ6/h43npuP7Uz2ZobQkSqgUIiQWzesZsHxs2he+vGXHN8+6DLEZEaQvdJJIg/vD+fop2ljLymL7VTlO0iUj30bZMAvlxUwNhp+Qz5SUe6tmoUdDkiUoMoJOLcjpIy7nlzNh2aNeDmk48IuhwRqWHU3RTnnvj3QlYX7eKNIf00DamIVDsdScSxaSs3M3z8cgb1a0fv7CZBlyMiNZBCIk6VlJVz15hZHN4ojTsHdAm6HBGpodTdFKee+WwJ32zYzouDe5Oeqo9JRIKhI4k4tHDdNp75fDEDc1pxUpfmQZcjIjWYQiLOlFc4d42dRcO0Otx/9tFBlyMiNZxCIs4MH7+cGauKeODsrjRpoImERCRYCok4sqpwJ098tJCTuzTnnJ6tgi5HREQhES9CEwnNJqWW8QdNJCQicUIhESfGTM3nv4s3cteAI2mVUS/ockREAIVEXNiwrZg/vD+f3tmZXNG3XdDliIh8SyERBx4cN5ddpeU8dkEPatVSN5OIxA+FRMA+mruOD2av47afdqJjs/SgyxER+Q6FRIC27CrlvrfncNThjbj+hA5BlyMi8j0KiQA99uF8Nm4v4U8X9KCOJhISkTikb6aAjF+ykdcmr+K6H3ege5vGQZcjIlIlhUQAdu0u5543Z5N9WH1+dUrnoMsREYkopiFhZgPMbKGZLTazu6tY/1czmxH+s8jMiiqtu8rMvgn/uSqWdVa3v32yiBWbdvLo+T2oV1cTCYlI/IrZGNRmlgI8DfwMyAemmNk4d5+3p427/7pS+1uAXuHHTYAHgFzAganhbTfHqt7qMiu/iOe/WsplfbLo1/GwoMsREdmnWB5J9AEWu/tSd98NjALO3Uf7y4DXwo9PAz5298JwMHwMDIhhrdWitLyCO8fMolnDVO4+/aigyxER2a9YhkRrYFWl5/nhZd9jZu2A9sCnB7KtmV1vZnlmlldQUHBIio6loV8uZcG6bTx8bjca16sTdDkiIvsVy5Co6tZhj9D2UmCMu5cfyLbuPtTdc909t1mzZgdZZvVYvGE7T33yDWd2P5xTj24ZdDkiIlGJZUjkA1mVnrcB1kRoeyn/19V0oNvGvYoK5543Z1GvbgoPnqOJhEQkccQyJKYAncysvZnVJRQE4/ZuZGZHApnAhEqLPwJONbNMM8sETg0vS0ivTFrBlOWbue+srjRrmBp0OSIiUYvZ1U3uXmZmNxP6ck8Bhrn7XDN7CMhz9z2BcRkwyt290raFZvYwoaABeMjdC2NVayytLtrFYx8u4MedmnLBMVWekhERiVtW6bs5oeXm5npeXl7QZXyHu3PN8ClMWlbIR786gawm9YMuSUTkO8xsqrvnRlqvO65jaNzMNXy2sIA7Tj1SASEiCUkhESObtpfw4Li55GRlcFX/7KDLERE5KAqJGHnovXlsLynjTxf2IEUTCYlIglJIxMCnC9bzzow1/PKkI+jcomHQ5YiIHDSFxCG2rbiU3701h84t0rnpxCOCLkdE5AdRSBxif/rXQtZtLebxC3pQt7b+eUUkselb7BCavKyQlyau4Or+7enVNjPockREfjCFxCFSXFrO3WNn0SazHnecpomERCQ5xOyO65rmfz/9hqUbd/DStX2oX1f/rCKSHHQkcQjMXa1XCKgAAAtaSURBVLOFf3yxlAuPbcOPO8X3aLQiIgdCIfEDlZVXcNfYWWTUr8u9Z2oiIRFJLuoX+YFe+O8y5qzeyjNXHENG/bpBlyMickjpSOIHWL5xB3/5eBGndm3B6d00kZCIJB+FxEFyd+5+cxZ1a9fi4YHdMNPQGyKSfBQSB2nUlFVMXFrI7844ihaN0oIuR0QkJhQSB2HdlmIeeX8+/TocxiW9s/a/gYhIglJIHCB357535rC7vIJHz++ubiYRSWoKiQP0wex1fDxvPbef2pnspg2CLkdEJKYUEgegaOduHhg3h+6tG3PN8e2DLkdEJOZ0n8QBePi9+RTtLGXkNX2pnaJ8FZHkp2+6KH25qICx0/IZ8pOOdG3VKOhyRESqhUIiCjtKyvjtW7Pp0KwBN5+siYREpOZQd1MUnvj3QlYX7eKNG/qRVicl6HJERKqNjiT2Y9rKzQwfv5wrj2tHbnaToMsREalWCol9KCkr564xszi8URp3DugSdDkiItVO3U378MxnS/hmw3ZeHNyb9FT9U4lIzaMjiQgWrd/GM58vZmBOK07q0jzockREAqGQqEJ5hXPnmFk0TKvD/WcfHXQ5IiKBUUhUYfj45cxYVcQDZ3elSQNNJCQiNZdCYi+rCnfyxEcLOblLc87p2SrockREAqWQqMTd+e1bs0mpZfxBEwmJiCgkKhszNZ+vvtnIXad3oVVGvaDLEREJnEIirGBbCX94fz59sptwRZ+2QZcjIhIXFBJhD46by67Sch69oDu1aqmbSUQEFBIAfDR3He/PXsttP+1Ex2bpQZcjIhI3anxIbNlVyn1vz6Hr4Y24/oQOQZcjIhJXavxYE7vLKuiZlcGtJ3eijiYSEhH5jph+K5rZADNbaGaLzezuCG0uNrN5ZjbXzF6ttLzczGaE/4yLVY3NGqby/KBcurdpHKu3EBFJWDE7kjCzFOBp4GdAPjDFzMa5+7xKbToB9wDHu/tmM6s8SNIud8+JVX0iIrJ/sTyS6AMsdvel7r4bGAWcu1eb64Cn3X0zgLtviGE9IiJygGIZEq2BVZWe54eXVdYZ6GxmX5vZRDMbUGldmpnlhZcPrOoNzOz6cJu8goKCQ1u9iIjE9MR1VTcbeBXv3wk4EWgDfGVm3dy9CGjr7mvMrAPwqZnNdvcl33kx96HAUIDc3Ny9X1tERH6gWB5J5ANZlZ63AdZU0eYddy9192XAQkKhgbuvCf+9FPgc6BXDWkVEpAqxDIkpQCcza29mdYFLgb2vUnobOAnAzJoS6n5aamaZZpZaafnxwDxERKRaxay7yd3LzOxm4CMgBRjm7nPN7CEgz93HhdedambzgHLgN+6+ycz6A/8wswpCQfZY5auiRESkeph7cnTl5+bmel5eXtBliIgkFDOb6u65EdcnS0iYWQGwohreqimwsRrepzoky74ky36A9iUeJct+QNX70s7dm0XaIGlCorqYWd6+UjeRJMu+JMt+gPYlHiXLfsDB7YsGKxIRkYgUEiIiEpFC4sANDbqAQyhZ9iVZ9gO0L/EoWfYDDmJfdE5CREQi0pGEiIhEpJAQEZGIFBJRMrPlZjY7PAlSQt21Z2bDzGyDmc2ptKyJmX1sZt+E/84MssZoRdiXB81sdaVJqs4IssZomFmWmX1mZvPDE27dFl6ecJ/LPvYlET+XNDObbGYzw/vy+/Dy9mY2Kfy5vB4eaiiu7WNfhpvZskqfyz7n7dE5iSiZ2XIg190T7qYaMzsB2A6MdPdu4WV/Agrd/bHwrIGZ7n5XkHVGI8K+PAhsd/cngqztQJjZ4cDh7j7NzBoCU4GBwGAS7HPZx75cTOJ9LgY0cPftZlYH+C9wG/D/gDfdfZSZPQfMdPdng6x1f/axL0OA99x9TDSvoyOJGsDdvwQK91p8LjAi/HgEof/UcS/CviQcd1/r7tPCj7cB8wnNt5Jwn8s+9iXheMj28NM64T8OnAzs+VJNlM8l0r4cEIVE9Bz4t5lNNbPrgy7mEGjh7msh9J8caL6f9vHuZjObFe6OivsumsrMLJvQUPiTSPDPZa99gQT8XMwsxcxmABuAj4ElQJG7l4WbVDWBWlzae1/cfc/n8sfw5/LXPSNuR6KQiN7x7n4McDrwy3C3h8SHZ4GOQA6wFngy2HKiZ2bpwFjgV+6+Neh6fogq9iUhPxd3L3f3HEJz4PQBjqqqWfVWdXD23hcz6wbcA3QBegNNgH12ZyokolRpEqQNwFuEfngS2fpwX/KePuWEnV/c3deH/zNUAM+TIJ9NuJ94LPCKu78ZXpyQn0tV+5Kon8se4RkyPweOAzLMbM/UClVNoBbXKu3LgHD3oLt7CfAi+/lcFBJRMLMG4RNymFkD4FRgzr63invjgKvCj68C3gmwlh9kz5dq2HkkwGcTPqn4AjDf3f9SaVXCfS6R9iVBP5dmZpYRflwPOIXQOZbPgAvDzRLlc6lqXxZU+iXECJ1b2efnoqubomChebbfCj+tDbzq7n8MsKQDYmavEZpHvCmwHniA0KyAo4G2wErgIneP+xPCEfblREJdGg4sB27Y068fr8zsR8BXwGygIrz4t4T68hPqc9nHvlxG4n0uPQidmE4h9Ev0aHd/KPwdMIpQ98x04Ofh38Tj1j725VOgGWDADGBIpRPc338dhYSIiESi7iYREYlIISEiIhEpJEREJCKFhIiIRKSQEBGRiBQSklDMzM3syUrP7wgP8PdDXzfVzD4Jj4p5yV7rBptZq4N4zSFmNmg/bXLN7H8O9LWjfP+IlzWG12eY2U2xeG9JHgoJSTQlwPlm1vQQv24voI6757j763utGwxUGRJmlhLpBd39OXcfua83dfc8d7/1QIs9RDIAhYTsk0JCEk0ZoXl6f733CjNrZ2b/CQ9c9h8za1tFmyZm9na4zUQz62FmzYGXgZzwkUTHSu0vBHKBV8Lr6llobpH7zey/wEVmdp2ZTQmP2z/WzOqHt33QzO4IP/7czB630Pj+i8zsx+HlJ5rZe5XaDwu3XWpmt1aq4z4zW2ChOSZe2/O6e+1bezObEK7l4UrL08P/HtMsNCfKueFVjwEdw/v15320kxpMISGJ6GngCjNrvNfyvxOaZ6IH8ApQVTfO74Hp4Ta/DbffAPwC+Cp8JLFkT+PwmPt5wBXhdbvCq4rd/UfuPorQPAO93b0noSEcro1Qd2137wP8itCd4lXpApxGaDydB8ysjpnlAhcQOto5n1BoVeUp4Fl37w2sq7S8GDgvPEDlScCT4SEZ7gaWhPfrN/toJzWYQkISTniE0ZHA3t00/YBXw49fAn5UxeY/Cq/D3T8FDqsibKJRuUuqm5l9ZWazgSuAoyNss2cQv6lAdoQ277t7SXhyqw1Ai3DN77j7rvB8De9G2PZ44LXw45cqLTfgETObBXxCaJjrFlVsH207qUFq77+JSFz6GzCN0CiWkVQ15kxVvxkfzNg0Oyo9Hg4MdPeZZjaY0FhSVdkz1k85kf/vVR4PaE+7A/ltvqp9uYLQWD3HunuphWZZTPsB7aQG0ZGEJKTwoHej+W7Xznjg0vDjKwhN17i3L8PrMLMTgY1RzOOwDWi4j/UNgbXh4bKv2G/xB+6/wNkWmrM4HTgzQruv+e7+79EY2BD+4j8JaBdevvd+RWonNZhCQhLZk4RGg93jVuDqcHfJlYTm893bg0BuuM1j/N+w3PsyHHhuz4nrKtbfR2j01o+BBVFXHyV3n0JoCPGZhLqs8oAtVTS9jdCEWFMIfeHv8Qqhfc4jFB4Lwq+7CfjazOaY2Z8jtZOaTaPAiiQAM0sPT2hfn9DR0PV75pUWiSWdkxBJDEPNrCuhcwQjFBBSXXQkISIiEemchIiIRKSQEBGRiBQSIiISkUJCREQiUkiIiEhE/x8eI/2qhWk7UwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# QUESTION C\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "result = {}\n",
    "filename = \"HandWrittenLetters.txt\"\n",
    "classes = \"ABCDEFGHIJ\"\n",
    "dataset = pickDataClass(filename, classes)\n",
    "number_per_class=39\n",
    "test_instances=[[0,5], [0,10], [0,15], [0,20], [0,25], [0,30], [0,35]]\n",
    "accuracies = []\n",
    "for test in test_instances:\n",
    "    train_attr, train_class, test_attr, test_class = splitData2TestTrain(dataset,number_per_class,test)\n",
    "    centroid = Centroid()\n",
    "    centroid.fit(train_attr, train_class)\n",
    "    y_pred = centroid.predict(test_attr)\n",
    "    accuracies.append(accuracy_score(test_class, y_pred))\n",
    "\n",
    "train_leng = [number_per_class-i[1] for i in test_instances]\n",
    "plt.plot(train_leng, accuracies)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('No of training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION D\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "result = {}\n",
    "filename = \"HandWrittenLetters.txt\"\n",
    "classes = \"KLMNOPQRST\"\n",
    "dataset = pickDataClass(filename, classes)\n",
    "number_per_class=39\n",
    "test_instances=[[0,5], [0,10], [0,15], [0,20], [0,25], [0,30], [0,35]]\n",
    "accuracies = []\n",
    "for test in test_instances:\n",
    "    train_attr, train_class, test_attr, test_class = splitData2TestTrain(dataset,number_per_class,test)\n",
    "    centroid = Centroid()\n",
    "    centroid.fit(train_attr, train_class)\n",
    "    y_pred = centroid.predict(test_attr)\n",
    "    accuracies.append(accuracy_score(test_class, y_pred))\n",
    "\n",
    "train_leng = [number_per_class-i[1] for i in test_instances]\n",
    "plt.plot(train_leng, accuracies)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('No of training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_attr, train_class, test_attr, test_class = splitData2TestTrain(dataset, 39,  i)\n",
    "SVClassifier(train_attr,train_class,test_attr,test_class)\n",
    "LogReg(train_attr,train_class,test_attr,test_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold\n",
    "X = np.array([[1, 2], [3, 4], [2, 2], [4, 3]])\n",
    "y = np.array([1, 1, 2, 2])\n",
    "kf = GroupKFold(n_splits=2)\n",
    "kf.get_n_splits(X)\n",
    "groups = np.array([0, 0, 2, 2])\n",
    "print(kf)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
